pred <- predict(fit2,test)
confusionMatrix(data = pred, testing$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
mysubtraining <- subset(training, select = c("diagnosis","IL_11", "IL_13", "IL_16", "IL_17E", "IL_1alpha",
"IL_3", "IL_4", "IL_5", "IL_6", "IL_6_Receptor", "IL_7", "IL_8"))
preProc <- preProcess(mysubtraining[,-13], method=c("center", "scale", "pca"), threshold=0.9)
preProc
preProc <- preProcess(mysubtraining[,-13], method=c("center", "scale", "pca"), threshold=0.85)
preProc
library(caret)
data(faithful)
set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
training <- faithful[inTrain,]
testing <- faithful[-inTrain,]
head(training)
library(caret)
data(faithful)
set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting, p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lm1 <- lm(eruptions ~waiting, data=trainFaith)
summary(lm1)
lines(trainFaith$waiting, lm1$fitted, lwd3)
lines(trainFaith$waiting, lm1$fitted, lwd=3)
lm1$fitted.values
lm1
lm1[1]
lm1[2]
lm1[3]
lm1$residuals
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
View(newdata)
predict(lm1, newdata)
predict(lm1, c(50, 60, 70, 80))
predict(lm1, data.frame(50, 60, 70, 80))
predict(lm1, data.frame(c(50, 60, 70, 80)))
predict(lm1, data.frame(waiting=c(10,20,70,80,90)))
par(mfrow=c(1,2))
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="red", xlab="Waiting (test)", ylab="Duration (test")
lines(testFaith$waiting, predict(lm1), lwd3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="red", xlab="Waiting (test)", ylab="Duration (test")
lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd3)
par(mfrow=c(1,2))
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd=3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="red", xlab="Waiting (test)", ylab="Duration (test")
lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd=3)
names(testFaith)
par(mfrow=c(1,2))
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd=3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="red", xlab="Waiting (test)", ylab="Duration (test")
lines(testFaith$waiting, predict(lm1, newdata=testFaith$waiting), lwd=3)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="Waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd=3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="red", xlab="Waiting (test)", ylab="Duration (test")
lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1, newdata=testFaith, interval="prediction")
pred1 <- predict(lm1, newdata=testFaith, interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty=c(1,1,1), lwd=3)
?matlines
ord
pred1[ord,]
modFit <- train(eruptions ~ waiting, data=TrainFaith, method="lm")
modFit <- train(eruptions ~ waiting, data=trainFaith, method="lm")
summary(modFit)
str(modFit)
summary(modFit$finalModel)
summary(lm1)
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#subset data to a training and testing set based on the Case variable in the data set
inTrain <- createDataPartition(y=segmentationOriginal$case, p=0.5, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
head(segmentationOriginal)
?subset
training <- subset(segmentationOriginal, case== "Train")
training <- subset(segmentationOriginal, segmentationOriginal$Case== "Train")
head(trainin)
head(training)
training <- subset(segmentationOriginal, Case== "Train")
str(segmentationOriginal)
summary(segmentationOriginal)
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case=="Testing")
dim(training)
dim(testing)
testing
training
head(segmentationOriginal)
testing <- subset(segmentationOriginal, Case=="Test")
dim(training)
dim(testing)
names(training)
modFit <- train(Class ~ ., method="rpart", data=training)
summary(modFit)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=True, all=TRUE, cex=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages("rattle")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#subset data to a training and testing set based on the Case variable in the data set
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case=="Test")
dim(training)
dim(testing)
#set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#subset data to a training and testing set based on the Case variable in the data set
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case=="Test")
dim(training)
dim(testing)
#set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
summary(modFit$finalModel)
print(modFit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit2 <- train(Area ~.., data=olive)
modFit2 <- train(Area ~., data=olive)
modFit2 <- train(Area ~., method="rpart" data=olive)
modFit2 <- train(Area ~., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
predict(modFit2, newdata=olive)
model <- rpart(Area ~., data=olive)
model
predict(model, newdata)
# Question 4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
#set seed to 13234
set.seed(13234)]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
#set seed to 13234
set.seed(13234)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
#set seed to 13234
set.seed(13234)
#fit a logistic regres
names(SAheart)
summary(SAheart)
str(SAheart)
modFit3 <- train(chd ~ age + alcohol + obesity, tobacco, typea + ldl, data=SAheart,
method="glm", family="binomial")
modFit3 <- train(chd ~ age + alcohol + obesity, tobacco, typea + ldl, data=trainSA,
method="glm", family="binomial")
modFit3 <- train(chd ~ age + alcohol + obesity, tobacco, typea + ldl, data=trainSA,method="glm", family="binomial")
modFit3 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm", family="binomial")
print(modFit3$finalModel)
predmodFit3 <- predict(modFit3, testSA)
values <- testSA
prediction <- predmodFit3
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
call(missClass(testSA, predmodFit3))
missClass(testSa, predmodFit3)
missClass(testSA, predmodFit3)
predmodFit3train <- predict(modFit3, trainSA)
predmodFit3test <- predict(modFit3, testSA)
missClass(trainSA,predmodFit3)
missClass(testSA, predmodFit3)
missClass(trainSA$chd,predmodFit3)
missClass(testSA$chd, predmodFit3)
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#subset data to a training and testing set based on the Case variable in the data set
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case=="Test")
dim(training)
dim(testing)
#set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 [PS]
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100 [WS]
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100 [PS]
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2 [Not possible to predict]
# Question 2
# - with a small K, bias is larger, and variance is smaller. also, in leave one out cross validation, K is equal to the sample size
# Question 3
library(pgmm)
data(olive)
olive = olive[,-1]
# fit a classification tree where Area is the outcome variable
modFit2 <- train(Area ~., method="rpart", data=olive)
# predict the value of area for the following data frame using the tree command with all defaults
model <- rpart(Area ~., data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
# Question 4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
#set seed to 13234
set.seed(13234)
#fit a logistic regression model (method="glm", family="binomial")
#chd (coronary heart disease) as the outcome
#age at onset (age), current alcohol consumption (alcohol), obseity levels (obesity),
#    cumulative tobacco (tobacco), type A behavior (typea), and
#    low density lipoprotein cholesterol as predictors (ldl)
modFit3 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm", family="binomial")
predmodFit3train <- predict(modFit3, trainSA)
predmodFit3test <- predict(modFit3, testSA)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predmodFit3)
missClass(testSA$chd, predmodFit3)
missClass(trainSA$chd,predmodFit3train)
# QUestion 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
#subset data to a training and testing set based on the Case variable in the data set
training <- subset(segmentationOriginal, Case== "Train")
testing <- subset(segmentationOriginal, Case=="Test")
dim(training)
dim(testing)
#set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 [PS]
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100 [WS]
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100 [PS]
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2 [Not possible to predict]
# Question 2
# - with a small K, bias is larger, and variance is smaller. also, in leave one out cross validation, K is equal to the sample size
# Question 3
library(pgmm)
data(olive)
olive = olive[,-1]
# fit a classification tree where Area is the outcome variable
modFit2 <- train(Area ~., method="rpart", data=olive)
# predict the value of area for the following data frame using the tree command with all defaults
model <- rpart(Area ~., data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
# Question 4
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size=dim(SAheart)[1]/2, replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
#set seed to 13234
set.seed(13234)
#fit a logistic regression model (method="glm", family="binomial")
#chd (coronary heart disease) as the outcome
#age at onset (age), current alcohol consumption (alcohol), obseity levels (obesity),
#    cumulative tobacco (tobacco), type A behavior (typea), and
#    low density lipoprotein cholesterol as predictors (ldl)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
modFit3 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,method="glm", family="binomial")
predmodFit3train <- predict(modFit3)
missClass(trainSA$chd,predmodFit3train)
predmodFit3test <- predict(modFit3, testSA)
missClass(testSA$chd, predmodFit3test)
1:dim(SAheart)[1]
?sample
train
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
modFit4 <- train(y ~., data=vowel.train, method="rf", prox=TRUE)
?varImp
varImp(modFit4)
varImp(modFit4$finalModel)
install.packages("randomForest")
install.packages("randomForest")
?randomForest
modFit4 <- randomForest(y ~., data=vowel.train, proximity=TRUE)
varImp(modFit4)
modFit4$importance
order(modFit4$importance)
varImp(modFit4)
varImp(modFit4$coefs)
modFit4
predmodFit4test <- predict(modFit4, vowel.test)
names(predmodFit4test)
varImp(predmodFit4test)
predmodFit4test
varImp(modFit4)
modFit4$importance
modFit4 <- randomForest(y ~., data=vowel.train, proximity=TRUE, importance=TRUE)
importance(modFit4)
varImp(modFit4, data="vowel.train")
varImp(modFit4)
# Course Project
# training data - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
mypath <- c("C:\\courseproj_ml")
setwd(mypath)
mydest_train <- c("pml-training.csv")
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile=mydest_train)
training <- read.csv(file=mydest_train, header=TRUE)
# test data - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
mydest_test <- c("pml-testing.csv")
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile=mydest_test)
testing <- read.csv(file=mydest_test, header=TRUE)
# The goal of your project is to predict the manner in which they did the exercise.
# This is the "classe" variable in the training set. You may use any of the other
# variables to predict with. You should create a report describing how you built
# your model, how you used cross validation, what you think the expected out of
# sample error is, and why you made the choices you did. You will also use your
# prediction model to predict 20 different test cases.
# data from accelerometers on: belt, forearm, arm, and dumbell of 6 participants
# barbell lifts performed correctly and incorrectly in 5 different ways
library(caret)
library(kernlab)
library(plyr)
library(dplyr)
library(rpart.plot)
library(rpart)
# removing near zero covariates
# zerovar TRUE means that there is only one distinct value in the predictor
# nzv TRUE means that the predictor is a near zero variance predictor
# consider removing all zerovar = TRUE or nzv = TRUE ; the identifiers
# and "classe" are all still intact
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsvind <- mutate(nsv, include=!(nsv$zeroVar|nsv$nzv))
trainingnew <- training[,nsvind$include]
mynas <- matrix(0, nrow=1, ncol = dim(trainingnew)[2])
for (i in 1:dim(trainingnew)[2]){
mynas[,i] <- sum(is.na(trainingnew[,i]))
}
#looks like columns 1:7, 11:26, 50:53, 57:62, 64:73, 86:88, 90 have 19216 NA values (out of 19622 obs)
removecols <- c(1:7, 11:26, 40, 50:53, 57:62, 64:73, 86:88, 90)
trainingnew2 <- trainingnew[,-removecols]
#remove the same columns from testing
testingnew <- testing[,nsvind$include]
testingnew2 <- testingnew[,-removecols]
#partition training set into training/test sets for cross validation
inTrain <- createDataPartition(trainingnew2$classe, p=0.6)[[1]]
validation <- trainingnew2[-inTrain,]
trainingnew3 <- trainingnew2[inTrain,]
trainingnew2 <- trainingnew3
dim(validation)
dim(trainingnew2)
# trees
mytree <- rpart(classe ~. ,method="class", data=trainingnew2)
predtree <- predict(mytree, validation)
conftree <- confusionMatrix(predtree, validation$classe)
rpart.plot(mytree,main="Classification Treet", extra=102, under=TRUE, faclen=0)
# random forest
library(randomForest)
myrf <- randomForest(classe ~., data=trainingnew2)
predrf <- predict(myrf, validation)
confrf <- confusionMatrix(predrf, validation$classe)
# boosting
mygbm <- train(classe ~., method="gbm", data=trainingnew2, verbose=FALSE, trControl=trainControl(method="cv", number=3))
predgbm <- predict(mygbm, validation)
confgbm <- confusionMatrix(predgbm, validation$classe)
confrf
conftree
conftree
conftree <- confusionMatrix(predtree, validation$classe)
predtree <- predict(mytree, validation)
conftree <- confusionMatrix(predtree, validation$classe)
# Course Project
# training data - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
mypath <- c("C:\\courseproj_ml")
setwd(mypath)
mydest_train <- c("pml-training.csv")
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile=mydest_train)
training <- read.csv(file=mydest_train, header=TRUE)
# test data - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
mydest_test <- c("pml-testing.csv")
# download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile=mydest_test)
testing <- read.csv(file=mydest_test, header=TRUE)
# The goal of your project is to predict the manner in which they did the exercise.
# This is the "classe" variable in the training set. You may use any of the other
# variables to predict with. You should create a report describing how you built
# your model, how you used cross validation, what you think the expected out of
# sample error is, and why you made the choices you did. You will also use your
# prediction model to predict 20 different test cases.
# data from accelerometers on: belt, forearm, arm, and dumbell of 6 participants
# barbell lifts performed correctly and incorrectly in 5 different ways
library(caret)
library(kernlab)
library(plyr)
library(dplyr)
library(rpart.plot)
library(rpart)
# removing near zero covariates
# zerovar TRUE means that there is only one distinct value in the predictor
# nzv TRUE means that the predictor is a near zero variance predictor
# consider removing all zerovar = TRUE or nzv = TRUE ; the identifiers
# and "classe" are all still intact
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsvind <- mutate(nsv, include=!(nsv$zeroVar|nsv$nzv))
trainingnew <- training[,nsvind$include]
mynas <- matrix(0, nrow=1, ncol = dim(trainingnew)[2])
for (i in 1:dim(trainingnew)[2]){
mynas[,i] <- sum(is.na(trainingnew[,i]))
}
#looks like columns 1:7, 11:26, 50:53, 57:62, 64:73, 86:88, 90 have 19216 NA values (out of 19622 obs)
removecols <- c(1:7, 11:26, 40, 50:53, 57:62, 64:73, 86:88, 90)
trainingnew2 <- trainingnew[,-removecols]
#remove the same columns from testing
testingnew <- testing[,nsvind$include]
testingnew2 <- testingnew[,-removecols]
#partition training set into training/test sets for cross validation
set.seed(234)
inTrain <- createDataPartition(trainingnew2$classe, p=0.6)[[1]]
validation <- trainingnew2[-inTrain,]
trainingnew3 <- trainingnew2[inTrain,]
trainingnew2 <- trainingnew3
dim(validation)
dim(trainingnew2)
# trees -
mytree <- rpart(classe ~. ,method="class", data=trainingnew2)
predtree <- predict(mytree, validation)
conftree <- confusionMatrix(predtree, validation$classe)
rpart.plot(mytree,main="Classification Treet", extra=102, under=TRUE, faclen=0)
# random forest
set.seed(234)
library(randomForest)
myrf <- randomForest(classe ~., data=trainingnew2)
predrf <- predict(myrf, validation)
confrf <- confusionMatrix(predrf, validation$classe)
# boosting
set.seed(234)
mygbm <- train(classe ~., method="gbm", data=trainingnew2, verbose=FALSE, trControl=trainControl(method="cv", number=3))
predgbm <- predict(mygbm, validation)
confgbm <- confusionMatrix(predgbm, validation$classe)
predtree <- predict(mytree, validation, type="class")
conftreee
conftree
conftree <- confusionMatrix(predtree, validation$classe)
conftree
confrf
confgbm
predrftesting <- predict(myrf, testingnew2)
predrftesting
knitr::opts_chunk$set(echo = TRUE)
predrftesting <- predict(myrf, testingnew2)
predrftesting
